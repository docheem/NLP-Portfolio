{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/docheem/NLP-Portfolio/blob/main/PR_Conv_Text_State_of_the_Art_Embeddings_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5I9mTwRU4gf"
      },
      "source": [
        "# Converting Text to Features Using State-of-the-Art Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stpebN65n8jK",
        "outputId": "0cea78e1-4f5e-4655-b155-6754f4d4013d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "#Importing modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "import string\n",
        "import csv\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer # used for preprocessing\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn import preprocessing\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import matplotlib.pyplot as plt # our main display package\n",
        "import plotly.graph_objects as go\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9xGNnzl1BiD"
      },
      "source": [
        "Establishing UTF-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF_o6bVtTQE6",
        "outputId": "e1d352ce-52e6-455c-9a98-2b69d6195ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSI_X3.4-1968\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "print(locale.getpreferredencoding())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "607IzdhtTM68"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYYBFzlxyUSN"
      },
      "source": [
        "#EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "bqvEYeglSyTu",
        "outputId": "80b52e77-45f2-4774-b945-29eee97220ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   comments                                        description  duration  \\\n",
              "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
              "1       265  With the same humor and humanity he exuded in ...       977   \n",
              "2       124  New York Times columnist David Pogue takes aim...      1286   \n",
              "\n",
              "     event   film_date  languages  main_speaker  \\\n",
              "0  TED2006  1140825600         60  Ken Robinson   \n",
              "1  TED2006  1140825600         43       Al Gore   \n",
              "2  TED2006  1140739200         26   David Pogue   \n",
              "\n",
              "                                        name  num_speaker  published_date  \\\n",
              "0  Ken Robinson: Do schools kill creativity?            1      1151367060   \n",
              "1       Al Gore: Averting the climate crisis            1      1151367060   \n",
              "2              David Pogue: Simplicity sells            1      1151367060   \n",
              "\n",
              "                                             ratings  \\\n",
              "0  [{'id': 7, 'name': 'Funny', 'count': 19645}, {...   \n",
              "1  [{'id': 7, 'name': 'Funny', 'count': 544}, {'i...   \n",
              "2  [{'id': 7, 'name': 'Funny', 'count': 964}, {'i...   \n",
              "\n",
              "                                       related_talks    speaker_occupation  \\\n",
              "0  [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...       Author/educator   \n",
              "1  [{'id': 243, 'hero': 'https://pe.tedcdn.com/im...      Climate advocate   \n",
              "2  [{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...  Technology columnist   \n",
              "\n",
              "                                                tags  \\\n",
              "0  ['children', 'creativity', 'culture', 'dance',...   \n",
              "1  ['alternative energy', 'cars', 'climate change...   \n",
              "2  ['computers', 'entertainment', 'interface desi...   \n",
              "\n",
              "                         title  \\\n",
              "0  Do schools kill creativity?   \n",
              "1  Averting the climate crisis   \n",
              "2             Simplicity sells   \n",
              "\n",
              "                                                 url     views  \n",
              "0  https://www.ted.com/talks/ken_robinson_says_sc...  47227110  \n",
              "1  https://www.ted.com/talks/al_gore_on_averting_...   3200520  \n",
              "2  https://www.ted.com/talks/david_pogue_says_sim...   1636292  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ad189da-e2f4-4c9e-a051-6d8887edca3c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>description</th>\n",
              "      <th>duration</th>\n",
              "      <th>event</th>\n",
              "      <th>film_date</th>\n",
              "      <th>languages</th>\n",
              "      <th>main_speaker</th>\n",
              "      <th>name</th>\n",
              "      <th>num_speaker</th>\n",
              "      <th>published_date</th>\n",
              "      <th>ratings</th>\n",
              "      <th>related_talks</th>\n",
              "      <th>speaker_occupation</th>\n",
              "      <th>tags</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>views</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4553</td>\n",
              "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
              "      <td>1164</td>\n",
              "      <td>TED2006</td>\n",
              "      <td>1140825600</td>\n",
              "      <td>60</td>\n",
              "      <td>Ken Robinson</td>\n",
              "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
              "      <td>1</td>\n",
              "      <td>1151367060</td>\n",
              "      <td>[{'id': 7, 'name': 'Funny', 'count': 19645}, {...</td>\n",
              "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
              "      <td>Author/educator</td>\n",
              "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
              "      <td>Do schools kill creativity?</td>\n",
              "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
              "      <td>47227110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>265</td>\n",
              "      <td>With the same humor and humanity he exuded in ...</td>\n",
              "      <td>977</td>\n",
              "      <td>TED2006</td>\n",
              "      <td>1140825600</td>\n",
              "      <td>43</td>\n",
              "      <td>Al Gore</td>\n",
              "      <td>Al Gore: Averting the climate crisis</td>\n",
              "      <td>1</td>\n",
              "      <td>1151367060</td>\n",
              "      <td>[{'id': 7, 'name': 'Funny', 'count': 544}, {'i...</td>\n",
              "      <td>[{'id': 243, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
              "      <td>Climate advocate</td>\n",
              "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
              "      <td>Averting the climate crisis</td>\n",
              "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
              "      <td>3200520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>124</td>\n",
              "      <td>New York Times columnist David Pogue takes aim...</td>\n",
              "      <td>1286</td>\n",
              "      <td>TED2006</td>\n",
              "      <td>1140739200</td>\n",
              "      <td>26</td>\n",
              "      <td>David Pogue</td>\n",
              "      <td>David Pogue: Simplicity sells</td>\n",
              "      <td>1</td>\n",
              "      <td>1151367060</td>\n",
              "      <td>[{'id': 7, 'name': 'Funny', 'count': 964}, {'i...</td>\n",
              "      <td>[{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
              "      <td>Technology columnist</td>\n",
              "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
              "      <td>Simplicity sells</td>\n",
              "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
              "      <td>1636292</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ad189da-e2f4-4c9e-a051-6d8887edca3c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ad189da-e2f4-4c9e-a051-6d8887edca3c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ad189da-e2f4-4c9e-a051-6d8887edca3c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "path = '/content/drive/MyDrive/DAtasets/ted_main.csv'\n",
        "\n",
        "ted_df = pd.read_csv(path)#, quoting=csv.QUOTE_NONE, sep=';', on_bad_lines='skip', encoding=None)\n",
        "ted_df.head(3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYno29wc_V2T",
        "outputId": "a8463cd6-5ae8-403d-cdb0-e2472b8e501a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Sir Ken Robinson makes an entertaining and pro...\n",
              "1       With the same humor and humanity he exuded in ...\n",
              "2       New York Times columnist David Pogue takes aim...\n",
              "3       In an emotionally charged talk, MacArthur-winn...\n",
              "4       You've never seen data presented like this. Wi...\n",
              "                              ...                        \n",
              "2545    Between 2008 and 2016, the United States depor...\n",
              "2546    How can you study Mars without a spaceship? He...\n",
              "2547    Science fiction visions of the future show us ...\n",
              "2548    In an unmissable talk about race and politics ...\n",
              "2549    With more than half of the world population li...\n",
              "Name: description, Length: 2550, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ted_df['description']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzFppUpJAN9u",
        "outputId": "b47444e2-e3fa-47c1-93b4-44b22b7aeee3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "comments               int64\n",
              "description           object\n",
              "duration               int64\n",
              "event                 object\n",
              "film_date              int64\n",
              "languages              int64\n",
              "main_speaker          object\n",
              "name                  object\n",
              "num_speaker            int64\n",
              "published_date         int64\n",
              "ratings               object\n",
              "related_talks         object\n",
              "speaker_occupation    object\n",
              "tags                  object\n",
              "title                 object\n",
              "url                   object\n",
              "views                  int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ted_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otsyY7Sq_Qi-",
        "outputId": "5e0c19de-6e0a-4e33-b2c3-629eee0de4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2550 entries, 0 to 2549\n",
            "Data columns (total 17 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   comments            2550 non-null   int64 \n",
            " 1   description         2550 non-null   object\n",
            " 2   duration            2550 non-null   int64 \n",
            " 3   event               2550 non-null   object\n",
            " 4   film_date           2550 non-null   int64 \n",
            " 5   languages           2550 non-null   int64 \n",
            " 6   main_speaker        2550 non-null   object\n",
            " 7   name                2550 non-null   object\n",
            " 8   num_speaker         2550 non-null   int64 \n",
            " 9   published_date      2550 non-null   int64 \n",
            " 10  ratings             2550 non-null   object\n",
            " 11  related_talks       2550 non-null   object\n",
            " 12  speaker_occupation  2544 non-null   object\n",
            " 13  tags                2550 non-null   object\n",
            " 14  title               2550 non-null   object\n",
            " 15  url                 2550 non-null   object\n",
            " 16  views               2550 non-null   int64 \n",
            "dtypes: int64(7), object(10)\n",
            "memory usage: 338.8+ KB\n"
          ]
        }
      ],
      "source": [
        "ted_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BgOONBw_RIg",
        "outputId": "cb81ba21-b2dd-41a1-a113-ccb1eadc3bf4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2550, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "ted_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH7RTs_y__l5",
        "outputId": "88dc11a1-340b-49f2-d04f-256129d0c9d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Do schools kill creativity?\n",
              "1        Averting the climate crisis\n",
              "2                   Simplicity sells\n",
              "3                Greening the ghetto\n",
              "4    The best stats you've ever seen\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "ted_df = ted_df['title'].astype(str)\n",
        "ted_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyiwiGMa-D7T"
      },
      "source": [
        "Text Data Processing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "299chW76d1H_"
      },
      "outputs": [],
      "source": [
        "# remove urls, handles, and the hashtag from hashtags\n",
        "def remove_urls(text):\n",
        "    new_text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split())\n",
        "    return new_text\n",
        "\n",
        "# make all text lowercase\n",
        "def text_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "# remove numbers\n",
        "def remove_numbers(text):\n",
        "    result = re.sub(r'\\d+', '', text)\n",
        "    return result\n",
        "\n",
        "# remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "# tokenize\n",
        "def tokenize(text):\n",
        "    text = word_tokenize(text)\n",
        "    return text\n",
        "\n",
        "# remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "\n",
        "    text = [i\n",
        "            for i\n",
        "            in text\n",
        "            if\n",
        "            not i\n",
        "            in stop_words]\n",
        "    return text\n",
        "\n",
        "# lemmatize\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(text):\n",
        "\n",
        "    text = [lemmatizer.lemmatize(token) for token in text]\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTxLbG9v-y_T"
      },
      "outputs": [],
      "source": [
        "def preprocessing(text):\n",
        "\n",
        "    text = text_lowercase(text)\n",
        "    text = remove_urls(text)\n",
        "    text = remove_numbers(text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = tokenize(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = lemmatize(text)\n",
        "    text = ' '.join(text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STNThXXTHZZ_",
        "outputId": "31ec43c0-f11a-4713-ea19-7994cad4ca6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['comments', 'description', 'duration', 'event', 'film_date',\n",
              "       'languages', 'main_speaker', 'name', 'num_speaker', 'published_date',\n",
              "       'ratings', 'related_talks', 'speaker_occupation', 'tags', 'title',\n",
              "       'url', 'views'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/DAtasets/ted_main.csv'\n",
        "\n",
        "ted_df = pd.read_csv(path)#, quoting=csv.QUOTE_NONE, sep=';', on_bad_lines='skip', encoding=None)\n",
        "ted_df.head(3)\n",
        "\n",
        "ted_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oret-8OqxjHI"
      },
      "source": [
        "# State-of-the-Art Embeddings with GloVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdW5BixR-zWN",
        "outputId": "b337701f-d40c-42a7-d29b-68e65818206c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#preprocessing input\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "for i in range(ted_df.shape[0]):\n",
        "    ted_df['description'][i] = preprocessing(str(ted_df['description'][i]))\n",
        "\n",
        "#in case if description has next line character\n",
        "for text in ted_df.description:\n",
        "    text=text.replace('\\n',' ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MULmxpgWTFZZ",
        "outputId": "2c6af4f4-b7d5-4af9-d591-e0a64ac32013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UTF-8\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "print(locale.getpreferredencoding())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXVt-o3OFgso"
      },
      "source": [
        "Generate a feature vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQPSTdhM-zW1",
        "outputId": "f6731c47-174a-4491-908b-78068bd6a1a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-03-12 17:25:08--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-03-12 17:25:08--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-03-12 17:25:09--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2023-03-12 17:27:48 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "ls: cannot access '!pwd': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#Implementations of above methods\n",
        "#GloVe:\n",
        "#loading pre-trained glove model\n",
        "#downloading and unzipping all word embeddings\n",
        "!export LC_ALL=en_US.UTF-8\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n",
        "!ls !pwd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUG_p3MuF7DC"
      },
      "outputs": [],
      "source": [
        "#importing 100-d glove model\n",
        "\n",
        "glove_model_100vec = pd.read_table(\"glove.6B.100d.txt\",\n",
        "                                   sep=\" \",\n",
        "                                   index_col = 0,\n",
        "                                   header = None,\n",
        "                                   quoting=csv.QUOTE_NONE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfkp48B5-zXr"
      },
      "outputs": [],
      "source": [
        "# Getting mean/average vector for each sentence\n",
        "\n",
        "def get_mean_vector(glove_model, words):\n",
        "    # remove out-of-vocabulary words\n",
        "    # assuming 100-d vector\n",
        "\n",
        "    words = [word\n",
        "             for word\n",
        "             in word_tokenize(words)\n",
        "             if word\n",
        "             in list(glove_model_100vec.index)] #if word is in vocab\n",
        "\n",
        "    if len(words) >= 1:\n",
        "        return np.mean(glove_model_100vec.loc[words].values, axis=0)\n",
        "\n",
        "    else:\n",
        "        return np.array([0]*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5uoGMUn1-zYn",
        "outputId": "c63a5423-c912-4fc4-a5c9-0a4e2498cacb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.11690753,  0.17445151,  0.04606778, ..., -0.48718723,\n",
              "         0.28744267,  0.16625453],\n",
              "       [-0.12658561,  0.17125735,  0.44709804, ..., -0.18936391,\n",
              "         0.51547109,  0.2958283 ],\n",
              "       [-0.06018609,  0.12372995,  0.27105957, ..., -0.38565426,\n",
              "         0.39135596,  0.2519755 ],\n",
              "       ...,\n",
              "       [-0.03596823,  0.15682215,  0.13904158, ..., -0.46336053,\n",
              "         0.47181896,  0.11201082],\n",
              "       [ 0.06819966,  0.22896074,  0.23709707, ..., -0.27244963,\n",
              "         0.17535124,  0.22864833],\n",
              "       [-0.00839048,  0.2554091 ,  0.35424354, ..., -0.30055352,\n",
              "         0.44468763,  0.16909846]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating empty list and appending all mean arrays for comparing cosine\n",
        "# similarities\n",
        "\n",
        "glove_vec = []\n",
        "\n",
        "for i in ted_df.description:\n",
        "\n",
        "    glove_vec.append(list(get_mean_vector(glove_model_100vec, i)))\n",
        "\n",
        "\n",
        "glove_vec = np.asarray(glove_vec)\n",
        "glove_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQzt-D3pxPED"
      },
      "source": [
        "# State-of-the-Art Embeddings with ELMo\n",
        "\n",
        "ELMo vectors are the vectors that are the function of a given sentence. The main advantage of this method is it can have different vectors of words under different contexts.\n",
        "\n",
        "Words with different contexts in different sentences are called polysemous words. ELMo can successfully handle words of this nature"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh -o Miniconda3-latest-MacOSX-x86_64.shbash Miniconda3-latest-MacOSX-x86_64.sh\n",
        "!conda create --name tf python=3.9\n",
        "!pip install --upgrade pip\n",
        "!pip install tensorflow\n",
        "!python3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udxEdjXrC0Qq",
        "outputId": "3382d237-9623-4d99-cd20-c9357aa682f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 42.9M  100 42.9M    0     0   138M      0 --:--:-- --:--:-- --:--:--  138M\n",
            "curl: (6) Could not resolve host: Miniconda3-latest-MacOSX-x86_64.sh\n",
            "/bin/bash: conda: command not found\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (23.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.51.3)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m2023-03-12 18:27:46.454818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-12 18:27:48.003822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-12 18:27:48.003935: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-12 18:27:48.003957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-12 18:27:52.598619: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "tf.Tensor(-76.25183, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4llHH6Zb-zbP"
      },
      "outputs": [],
      "source": [
        "#Load pre-trained model\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tf.compat.v1.reset_default_graph()\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "embed_ = hub.Module(\"https://tfhub.dev/google/elmo/3\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezE3395u-zdl"
      },
      "outputs": [],
      "source": [
        "# function to average word vectors of each sentence\n",
        "\n",
        "def elmo_vectors_sentence(x):\n",
        "\n",
        "  sentence_embeddings = embed_(x.tolist(),\n",
        "                               signature = \"default\",\n",
        "                              as_dict = True)[\"elmo\"]\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    sess.run(tf.tables_initializer())\n",
        "\n",
        "    # Average of each vector\n",
        "    return sess.run(tf.reduce_mean(sentence_embeddings,1))\n",
        "\n",
        "#if your data set is large , make a batch of 100 samples. Just remove comment and run the code given below. As we have just 100 samples, we are not doing this\n",
        " #samples= [df[i:i+100] for i in range(0,df.shape[0],100)]\n",
        " # elmo_vec = [elmo_vectors_sentence(x['description']) for x in samples]\n",
        " #elmo_vec_full= np.concatenate(elmo_vec, axis = 0)\n",
        "#embeddings on our dataset\n",
        "elmo_vec = elmo_vectors_sentence(ted_df['description'])\n",
        "elmo_vec\n",
        "\n",
        "\n",
        "sess = tf.compat.v1.Session()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKshDB_0d1qx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfu46mJnd1sl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXvsPfeZd1u5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1hQK-OjuZArnIPg8hmGfdjiukNFK8TfoP",
      "authorship_tag": "ABX9TyMdZ8KbfE7TUOBwQ515/6LK",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}