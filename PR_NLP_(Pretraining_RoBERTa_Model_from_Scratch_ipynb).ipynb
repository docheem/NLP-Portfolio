{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "authorship_tag": "ABX9TyNSP8tQi487mDLAQSuuqd28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/docheem/NLP-Portfolio/blob/main/PR_NLP_(Pretraining_RoBERTa_Model_from_Scratch_ipynb).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretraining RoBERTa Model from Scratch\n",
        "We will be building a pretrained transformer model from scratch, that can perform language modeling on masked tokens.\n",
        "\n",
        "The model name is KantaiBERT and it will use:\n",
        "- A custom dataset\n",
        "- Train a tokenizer\n",
        "- Train the transformer model\n",
        "- Save it\n",
        "- Run it with an MLM example"
      ],
      "metadata": {
        "id": "nOVllGSv-8lG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy5S-_oT-wMH",
        "outputId": "ecea6be9-0906-4601-d763-faa3c4fb821a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 10.7M  100 10.7M    0     0  28.1M      0 --:--:-- --:--:-- --:--:-- 28.1M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://raw.githubusercontent.com/Denis2054/Transformers-for-NLP-2nd-Edition/master/Chapter04/kant.txt --output \"kant.txt\"\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Hugging Face transformers"
      ],
      "metadata": {
        "id": "i4xqvVkzkk0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We won't need TensorFlow here\n",
        "!pip uninstall -y tensorflow\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFNfisoMlIEr",
        "outputId": "e795f7d8-a0ed-475d-9850-bb5b86186f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.11.0\n",
            "Uninstalling tensorflow-2.11.0:\n",
            "  Successfully uninstalled tensorflow-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install `transformers` from master\n",
        "\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "\n",
        "# transformers version at notebook update --- 2.9.1\n",
        "# tokenizers version at notebook update --- 0.7.0\n",
        "\n",
        "!pip list | grep -E 'transformers|tokenizers'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr8ndpQAlIHR",
        "outputId": "366ea7a0-ea23-4bbf-d93f-cf73a88b85e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-_869cyw5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-_869cyw5\n",
            "  Resolved https://github.com/huggingface/transformers to commit b29e2dcaff114762e65eaea739ba1076fc5d1c84\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (1.22.4)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (4.0.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.27.0.dev0-py3-none-any.whl size=6633262 sha256=d6f054f149d5641e378a0065a6aef97a64973954a19ac527e7a3f95a8c12f745\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rffvtem7/wheels/42/68/45/c63edff61c292f2dfd4df4ef6522dcbecc603e7af82813c1d7\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.27.0.dev0\n",
            "tokenizers                    0.13.2\n",
            "transformers                  4.27.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training a tokenizer from scratch\n",
        "\n",
        "Kant.txt will be used to train the ByteLevelBPETokenizer() for Hugging Face. A BPE tokenizer will separate a string or word into substrings or subwords. 2 main advantages: \n",
        "- Words can be reduced to their simplest forms using the tokenizer. Then, it will combine these minor elements to create statistically intriguing ones. It is possible to change the words \"smaller\" and \"smallest\" into \"small,\" \"er,\" and \"est.\" The tokenizer is capable of more. For example, we might receive \"sm\" and \"all.\" In any case, the words are divided into smaller subword tokens and subword components, such as \"sm\" and \"all,\" rather than just \"small.\"\n",
        "- Sections of strings that are labeled as unknown, unk_token, using WordPiece level encoding, will practically disappear.\n"
      ],
      "metadata": {
        "id": "cb_4HCF8lsdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will be training the tokenizer with the following parameters\n",
        "\n",
        "- files = paths is the path to the dataset\n",
        "- vocab_size = 52_000 is the size of our tokenizerâ€™s model length\n",
        "- min_frequency threshold,  is the minimum frequency threshold\n",
        "- special_tokens = [] is a list of special tokens.\n",
        "\n"
      ],
      "metadata": {
        "id": "iboPl_nOp3Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the list of special tokens is, \n",
        "# <s>: a start token\n",
        "# <pad>: a padding token, </s>: an end token,\n",
        "# <unk>: an unknown token \n",
        "# <mask>: the mask token for language modeling\n",
        "\n",
        "\n",
        "%%time \n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "\n",
        "\n",
        "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "\n",
        "\n",
        "\n",
        "# Initialize a tokenizer\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "\n",
        "# Customize training\n",
        "\n",
        "tokenizer.train(files=paths, \n",
        "                \n",
        "                vocab_size = 52_000,\n",
        "\n",
        "                min_frequency = 2,\n",
        "\n",
        "                special_tokens = [\"<s>\",\n",
        "                                  \"<pad>\",\n",
        "                                  \"</s>\", \n",
        "                                  \"<unk>\",\n",
        "                                  \"<mask>\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSU0TkrelIJY",
        "outputId": "94a731fc-4a18-488e-c0f6-e4cc4d5d7ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.2 s, sys: 2.74 s, total: 14 s\n",
            "Wall time: 1.63 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our tokenizer is trained and ready to be saved.\n"
      ],
      "metadata": {
        "id": "PmiBuXlhtNof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the files to disk\n",
        "\n",
        "\n",
        "The tokenizer will generate two files when trained:\n",
        "\n",
        "- merges.txt, which contains the merged tokenized substrings\n",
        "\n",
        "- vocab.json, which contains the indices of the tokenized substrings"
      ],
      "metadata": {
        "id": "dX355ZuotTmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "token_dir = '/content/KantaiBERT'\n",
        "\n",
        "\n",
        "if not os.path.exists(token_dir):\n",
        "  \n",
        "  os.makedirs(token_dir)\n",
        "\n",
        "\n",
        "tokenizer.save_model('KantaiBERT')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCwN91N_lILi",
        "outputId": "40a18529-721e-465e-fc35-bf7577bbe7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['KantaiBERT/vocab.json', 'KantaiBERT/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the trained tokenizer files"
      ],
      "metadata": {
        "id": "CL5Dkj4Et9ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\"./KantaiBERT/vocab.json\",\n",
        "                                  \"./KantaiBERT/merges.txt\",)\n"
      ],
      "metadata": {
        "id": "YlQjJmPUlINy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our tokenizer is able to encode a sequence\n",
        "\n",
        "#Encoding a sequence\n",
        "tokenizer.encode(\"The Critique of Pure Reason.\").tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOWfZqCmuS6n",
        "outputId": "ca295e50-fee7-41cd-9e6e-8da46d6a3c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'Ä Critique', 'Ä of', 'Ä Pure', 'Ä Reason', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also ask to see the number of tokens in this sequence\n",
        "\n",
        "tokenizer.encode(\"The Critique of Pure Reason.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt-0zOK8ulHs",
        "outputId": "38204fd7-1fc0-4b4e-b977-e19ae2912a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=6, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tokenizer now processes the tokens to fit the BERT model variant. The post-processor will add a start and end token."
      ],
      "metadata": {
        "id": "yx2DkYB5vJGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for example\n",
        "\n",
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    \n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "metadata": {
        "id": "NrmSnd_lulSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Letâ€™s encode a post-processed sequence\n",
        "\n",
        "tokenizer.encode(\"The Critique of Pure Reason.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD99Q9aDulY5",
        "outputId": "ffb36a35-dbf3-490c-f292-be903fed865a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=8, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we want to see what was added, \n",
        "# we can ask the tokenizer to encode \n",
        "# the post-processed sequence\n",
        "\n",
        "tokenizer.encode(\"The Critique of Pure Reason.\").tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bklSSm0fv2de",
        "outputId": "8552af0c-7f34-4c5d-92c0-c3885317063e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'The', 'Ä Critique', 'Ä of', 'Ä Pure', 'Ä Reason', '.', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4vS7WyewLkr",
        "outputId": "0d2869e9-b003-426e-ed2a-4c7c94476de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 28 21:36:00 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Model configuration "
      ],
      "metadata": {
        "id": "9CWpctG-w7-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "\n",
        "\n",
        "config = RobertaConfig(vocab_size = 52_000,\n",
        "                       \n",
        "                       max_position_embeddings = 514,\n",
        "\n",
        "                       num_attention_heads = 12,\n",
        "\n",
        "                       num_hidden_layers = 6,\n",
        "\n",
        "                       type_vocab_size = 1)\n",
        "                      "
      ],
      "metadata": {
        "id": "bp_cw6ypw_l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reloading the tokenizer in transformers"
      ],
      "metadata": {
        "id": "wgi4LCwkxgdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"./KantaiBERT\",\n",
        "                                             max_length = 512)"
      ],
      "metadata": {
        "id": "h2RHdSI9w_os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializing a model from scratch"
      ],
      "metadata": {
        "id": "QKv3Mfv2xtYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config = config)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xvkmxGew_ra",
        "outputId": "da70cad8-8443-4985-afb6-c381cc12441c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobertaForMaskedLM(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lm_head): RobertaLMHead(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (decoder): Linear(in_features=768, out_features=52000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring model parameters"
      ],
      "metadata": {
        "id": "FdtmU8T0yanz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The model is small and contains',\n",
        "      model.num_parameters(),\n",
        "      'parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25PTVRVmw_uo",
        "outputId": "f8e0aceb-b7e9-4956-9cd5-5675debd6477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model is small and contians 83504416 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the length of the list of parameters\n",
        "\n",
        "LP = list(model.parameters())\n",
        "\n",
        "lp=len(LP)\n",
        "print(lp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmt4nQGgw_wE",
        "outputId": "3405f2f3-dd2f-4174-d411-63fd52df2079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the 106 matrices and vectors \n",
        "# in the tensors that contain them\n",
        "\n",
        "#for p in range(0,lp):\n",
        "  #print(LP[p])\n"
      ],
      "metadata": {
        "id": "jfDYUqVSzzqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of parameters is calculated by taking all parameters in the model and adding them\n",
        "up; for example:\n",
        "- The vocabulary (52,000) x dimensions (768)\n",
        "- The size of the vectors is 1 x 768\n",
        "- The many other dimensions found"
      ],
      "metadata": {
        "id": "KWdVwFqA0eAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the parameters\n",
        "\n",
        "np = 0\n",
        "\n",
        "for p in range(0,lp):#number of tensors\n",
        "  \n",
        "  PL2 = True\n",
        "  \n",
        "  try:\n",
        "    L2 = len(LP[p][0]) #check if 2D\n",
        "  \n",
        "  except:\n",
        "    \n",
        "    L2 = 1             #not 2D but 1D\n",
        "    \n",
        "    PL2 = False\n",
        "  \n",
        "  L1 = len(LP[p])      \n",
        "  \n",
        "  L3 = L1*L2\n",
        " \n",
        "  np + = L3             # number of parameters per tensor\n",
        "  \n",
        "  \n",
        "  if PL2 == True:\n",
        "\n",
        "    print(p,L1,L2,L3)  # displaying the sizes of the parameters\n",
        "    \n",
        "  \n",
        "  if PL2 == False:\n",
        "\n",
        "    print(p,L1,L3)  # displaying the sizes of the parameters\n",
        "\n",
        "\n",
        "print(np)              # total number of parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJcmUSz-0AYz",
        "outputId": "6500b9d7-1597-4392-d7f2-aa6d43dbac0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 52000 768 39936000\n",
            "1 514 768 394752\n",
            "2 1 768 768\n",
            "3 768 768\n",
            "4 768 768\n",
            "5 768 768 589824\n",
            "6 768 768\n",
            "7 768 768 589824\n",
            "8 768 768\n",
            "9 768 768 589824\n",
            "10 768 768\n",
            "11 768 768 589824\n",
            "12 768 768\n",
            "13 768 768\n",
            "14 768 768\n",
            "15 3072 768 2359296\n",
            "16 3072 3072\n",
            "17 768 3072 2359296\n",
            "18 768 768\n",
            "19 768 768\n",
            "20 768 768\n",
            "21 768 768 589824\n",
            "22 768 768\n",
            "23 768 768 589824\n",
            "24 768 768\n",
            "25 768 768 589824\n",
            "26 768 768\n",
            "27 768 768 589824\n",
            "28 768 768\n",
            "29 768 768\n",
            "30 768 768\n",
            "31 3072 768 2359296\n",
            "32 3072 3072\n",
            "33 768 3072 2359296\n",
            "34 768 768\n",
            "35 768 768\n",
            "36 768 768\n",
            "37 768 768 589824\n",
            "38 768 768\n",
            "39 768 768 589824\n",
            "40 768 768\n",
            "41 768 768 589824\n",
            "42 768 768\n",
            "43 768 768 589824\n",
            "44 768 768\n",
            "45 768 768\n",
            "46 768 768\n",
            "47 3072 768 2359296\n",
            "48 3072 3072\n",
            "49 768 3072 2359296\n",
            "50 768 768\n",
            "51 768 768\n",
            "52 768 768\n",
            "53 768 768 589824\n",
            "54 768 768\n",
            "55 768 768 589824\n",
            "56 768 768\n",
            "57 768 768 589824\n",
            "58 768 768\n",
            "59 768 768 589824\n",
            "60 768 768\n",
            "61 768 768\n",
            "62 768 768\n",
            "63 3072 768 2359296\n",
            "64 3072 3072\n",
            "65 768 3072 2359296\n",
            "66 768 768\n",
            "67 768 768\n",
            "68 768 768\n",
            "69 768 768 589824\n",
            "70 768 768\n",
            "71 768 768 589824\n",
            "72 768 768\n",
            "73 768 768 589824\n",
            "74 768 768\n",
            "75 768 768 589824\n",
            "76 768 768\n",
            "77 768 768\n",
            "78 768 768\n",
            "79 3072 768 2359296\n",
            "80 3072 3072\n",
            "81 768 3072 2359296\n",
            "82 768 768\n",
            "83 768 768\n",
            "84 768 768\n",
            "85 768 768 589824\n",
            "86 768 768\n",
            "87 768 768 589824\n",
            "88 768 768\n",
            "89 768 768 589824\n",
            "90 768 768\n",
            "91 768 768 589824\n",
            "92 768 768\n",
            "93 768 768\n",
            "94 768 768\n",
            "95 3072 768 2359296\n",
            "96 3072 3072\n",
            "97 768 3072 2359296\n",
            "98 768 768\n",
            "99 768 768\n",
            "100 768 768\n",
            "101 52000 52000\n",
            "102 768 768 589824\n",
            "103 768 768\n",
            "104 768 768\n",
            "105 768 768\n",
            "83504416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the dataset"
      ],
      "metadata": {
        "id": "HKkCsWzr2LE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "\n",
        "dataset = LineByLineTextDataset(tokenizer = tokenizer,\n",
        "                                \n",
        "                                file_path=\"./kant.txt\",\n",
        "                                \n",
        "                                block_size = 128)\n",
        "\n",
        "#from transformers import ByteLevelBPETokenizer\n",
        "\n",
        "#tokenizer = ByteLevelBPETokenizer(\"path/to/vocab.json\", \"path/to/merges.txt\")\n",
        "#text = \"This is an example text to tokenize.\"\n",
        "\n",
        "# Tokenize the text\n",
        "#encoding = tokenizer.encode(text)\n",
        "\n",
        "# Print the token IDs and corresponding tokens\n",
        "#for id, token in zip(encoding.ids, encoding.tokens):\n",
        "    #print(f\"{id}\\t{token}\")\n",
        "\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i9aGBdA0Acj",
        "outputId": "9c386403-9a06-4346-a65c-3d9173acde7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/data/datasets/language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 41.5 s, sys: 1.58 s, total: 43.1 s\n",
            "Wall time: 41.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a data collator\n",
        "\n",
        "The program will now define a data collator to create an object for backpropagation.\n",
        "\n",
        "A data collator will take samples from the dataset and collate them into batches.\n",
        "\n",
        "We are preparing a batched sample process for MLM by setting\n",
        "- mlm = True.\n",
        "- We also set the number of masked tokens to train mlm_probability = 0.15, This will determine\n",
        "the percentage of tokens masked during the pretraining process.\n"
      ],
      "metadata": {
        "id": "A9mBStdP5AiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now initialize data_collator with our tokenizer, MLM activated, and the proportion of\n",
        "masked tokens set to 15 percent"
      ],
      "metadata": {
        "id": "kz7w1oXm54tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize data_collator with our tokenizer\n",
        "\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer,\n",
        "                                                \n",
        "                                                mlm = True, \n",
        "                                                \n",
        "                                                mlm_probability = 0.15)"
      ],
      "metadata": {
        "id": "yzIbEGkG0Adw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the trainer\n"
      ],
      "metadata": {
        "id": "jv64se5W6Mni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"./KantaiBERT\",\n",
        "                                  \n",
        "                                  overwrite_output_dir = True,\n",
        "\n",
        "                                  num_train_epochs = 1,\n",
        "\n",
        "                                  per_device_train_batch_size = 64,\n",
        "\n",
        "                                  save_steps = 10_000,\n",
        "\n",
        "                                  save_total_limit = 2)\n"
      ],
      "metadata": {
        "id": "BEJcvjqp0Aio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model = model,\n",
        "                  \n",
        "                  args = training_args,\n",
        "\n",
        "                  data_collator = data_collator,\n",
        "                  \n",
        "                  train_dataset = dataset)\n",
        "   "
      ],
      "metadata": {
        "id": "XptMpDF-7VRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretraining the model"
      ],
      "metadata": {
        "id": "L3OQrzq60OXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "b8M39usR7rWe",
        "outputId": "083cd9b5-5db7-4866-ce17-ba91fd9491bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:346: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2672' max='2672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2672/2672 03:04, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.609800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.743600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>5.264700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>4.854100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 5s, sys: 1.27 s, total: 3min 6s\n",
            "Wall time: 3min 7s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2672, training_loss=5.451993177037039, metrics={'train_runtime': 187.4363, 'train_samples_per_second': 912.118, 'train_steps_per_second': 14.256, 'total_flos': 873620128952064.0, 'train_loss': 5.451993177037039, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the final model (+tokenizer + config) to disk"
      ],
      "metadata": {
        "id": "yVG_0WLd7uaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./KantaiBERT\")"
      ],
      "metadata": {
        "id": "MwEy7G2l7wfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Language modeling with FillMaskPipeline\n"
      ],
      "metadata": {
        "id": "OpvZwrm17zAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "fill_mask = pipeline(\"fill-mask\",\n",
        "                     \n",
        "                     model=\"./KantaiBERT\",\n",
        "                     \n",
        "                     tokenizer=\"./KantaiBERT\")"
      ],
      "metadata": {
        "id": "9_dDmspu8G9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask(\"Father, mother and <mask>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5gMjWR_8R0J",
        "outputId": "ca01faab-a94a-4def-9f50-ad0426f194cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.06342872977256775,\n",
              "  'token': 18,\n",
              "  'token_str': '.',\n",
              "  'sequence': 'Father, mother and.'},\n",
              " {'score': 0.014288828708231449,\n",
              "  'token': 267,\n",
              "  'token_str': ' the',\n",
              "  'sequence': 'Father, mother and the'},\n",
              " {'score': 0.009417579509317875,\n",
              "  'token': 396,\n",
              "  'token_str': ' are',\n",
              "  'sequence': 'Father, mother and are'},\n",
              " {'score': 0.007689234334975481,\n",
              "  'token': 650,\n",
              "  'token_str': ' without',\n",
              "  'sequence': 'Father, mother and without'},\n",
              " {'score': 0.00540144881233573,\n",
              "  'token': 288,\n",
              "  'token_str': ' to',\n",
              "  'sequence': 'Father, mother and to'}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we built KantaiBERT, a RoBERTa-like model transformer, from scratch using the building blocks provided by Hugging Face"
      ],
      "metadata": {
        "id": "vK7HcLPFDNng"
      }
    }
  ]
}