{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/docheem/NLP-Portfolio/blob/main/Video_to_text_Transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo we will be using a library call whisper from Open AI to transcribe a youtube videos to texts."
      ],
      "metadata": {
        "id": "WOvAVvo0MQlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!pip install pytube\n",
        "\n",
        "!pip install jiwer\n",
        "\n",
        "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcZiwppCMgtW",
        "outputId": "1759ae6f-1270-472c-c48e-258d63bcbc2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-bhgqt16o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-bhgqt16o\n",
            "  Resolved https://github.com/openai/whisper.git to commit 7858aa9c08d98f75575035ecd6481f462d66ca27\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.26.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.8/dist-packages (12.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.8/dist-packages (2.5.1)\n",
            "Requirement already satisfied: levenshtein==0.20.2 in /usr/local/lib/python3.8/dist-packages (from jiwer) (0.20.2)\n",
            "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from levenshtein==0.20.2->jiwer) (2.13.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-1kfdf7td\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-1kfdf7td\n",
            "  Resolved https://github.com/openai/whisper.git to commit 7858aa9c08d98f75575035ecd6481f462d66ca27\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179424 sha256=8eaf9e04ca9c83a4d6e682c979ce87d753ebf83a9f513b1540c0e4684c1a2bee\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tzcoe5uv/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "  Attempting uninstall: openai-whisper\n",
            "    Found existing installation: openai-whisper 20230124\n",
            "    Uninstalling openai-whisper-20230124:\n",
            "      Successfully uninstalled openai-whisper-20230124\n",
            "Successfully installed openai-whisper-20230124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1THkEoXiFGqC"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QxVAiYThFGqE"
      },
      "outputs": [],
      "source": [
        "link='https://www.youtube.com/watch?v=PH_eb1udpew&t=321s'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cgzjYcmBFGqE"
      },
      "outputs": [],
      "source": [
        "try: \n",
        "    you_t = YouTube(link) \n",
        "\n",
        "except: \n",
        "    print(\"Error Connection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ibA2bGLuFGqF",
        "outputId": "25ecfa7d-5be7-4022-9170-ef5bff233b9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"24fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"24fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"299\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"48fps\" vcodec=\"avc1.64002a\" progressive=\"False\" type=\"video\">, <Stream: itag=\"298\" mime_type=\"video/mp4\" res=\"720p\" fps=\"48fps\" vcodec=\"avc1.640020\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"24fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"24fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"24fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"24fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "you_t.streams.filter(file_extension='mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_mj3iS5eFGqF"
      },
      "outputs": [],
      "source": [
        "stream = you_t.streams.get_by_itag(139)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EBbeebEZFGqG",
        "outputId": "05ac563f-a115-4067-8eab-5be8ae92ecfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/GoogleImagen.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "stream.download('',\"GoogleImagen.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"GoogleImagen.mp4\")\n",
        "result['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "qJwhMsOhJgQm",
        "outputId": "8e6ed830-337b-4532-8170-f2b6410329a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi everyone, welcome to my channel. This is another video in our NLP beginner to advanced series and today we will look at what is zero short learning or zero short classification. We will see what exactly zero short learning or classification mean. How does zero short learning model works under the hood and then finally we will do a zero short classification using hugging face transformer. So first of all what exactly is a zero short learning. In a zero short learning we are going to use a model to do a prediction on a task for which it hasn't been trained on. For example, let's look at we want to do a classification given a particular sentence here. We want to know whether the sentence is about travel, cooking or dancing. So our classification labels are travel, cooking and dancing and we know that the model that we are going to use is not explicitly trained on such a labels, but we still going to use it and that is the reason we call it zero short classification. Then how does this zero short classification model works if they haven't trained on explicitly on our kind of labels. The one of the popular technique zero short learning models uses called natural language inference, this one NLI natural language inference. Now what exactly the natural language inference task, the natural language inference task is we want to determine whether particular hypothesis is a true false or a neutral given some premise. Okay, here is an example. Let's say we have a sentence one day I will see the world. So you can treat this sentence as a premise and then you can calculate or you can create hypothesis for your each label. So if you have a label travel, we can say that this particular sentence which is our premise, this text is about travel. Similarly, you will do for cooking, this text is about cooking. So once you have each label once you have a hypothesis created, then you can use this technique NLI and you can calculate given the sentence one day I will see the world. What is the probability that it is the true for each of these hypothesis? What is the probability that this text is about travel? What is the probability that this text is about cooking? And you are going to calculate what is the probability for a true and that is how you are going to use it. And we are going to use a model called this one, the Facebook, but large MNLI actually it is stand for I think multi NLI, multi NLI. And this particular model is trained on this dataset and we will see why does doing this kind of premise and hypothesis classification work. So if you look at the dataset on which it has been trained, let's open this in a dataset viewer. Here is the dataset that has been used to train that zero short learning model. It has two important column, this one which is the premise and this one which is the hypothesis, both are string or sentences and finally you have a label. So given this particular premise and this hypothesis, we want to classify whether the particular this hypothesis is a true which is entailment or is it neutral or is it a contradiction. So you could see this NLI natural language inference, it treated as a classification problem. Given the two sentences which is premise and hypothesis, we train a model to classify whether they are true neutral or contradiction. And that is what we are going to see how we can do the zero short classification using let's say transform a library. So first thing we will do, let's install the transform a library using PIP install. And once it install, we want to import the pipeline module of the transform and what does pipeline model does, the pipeline models take the name of the task that we want to perform and you can specify the model that we want to use. This particular name, we have copied from here, you can simply copy from here this name. And we want to load the zero short classification model here. So let's run this thing. And once you have this model loaded in this variable, let's say classified, we will declare the sequence that we want to classify. So this is the sentence that we want to classify. One day I will see the world. And then you give the list of labels that you want to consider while classification. So we say that travel, cooking and dancing. And then you give these two, both the information to your classified that we loaded here. And then eventually it will print the score for each of these labels. So you could see this is our sequence and for a travel, we got this 0.99 score for dancing. We got very low score and for cooking also we got very low score. So under the hood, this particular pipeline, the zero short classification, it has performed the above task. It has taken our sequence and then it has created the hypothesis for our each of this label. And then it has used the pre-trained model, this one, which is specifically trained on the premise and hypothesis classification. And then it has given the score for each of these labels. So you could see we got the high score for the travel. Now it is possible that these sequence or sentence can belong to more than one label, which is a multi label classification case. In that case, we can provide one more flag during the classification, which is multi label is equal to true. So let's add one more label. So I added label called exploration. Now we know that our sentence one day I will see the world is related to both travel and the exploration. And let's see what score we get. You could see for travel we got 0.99 for exploration, we got some high score and other two we got. So this is how powerful zero short learning. So most of the time you want to do some classification, but you don't have enough training data. If you want to train any model from the scratch, you might require a thousands of training examples. Even if you want to use a pre-trained model and fine tune it, you still require a few hundred examples. But then you could first explore whether the zero short learning works in your case or not. And you could see it is very much powerful. Let's try it on another example, our different labels totally. So we will try this sentence. A Donald Trump will be the next president. And we will see a candidate label we will give a science, politics and history. And we will see what is the score for each of them. And here's the output you could see. We got very high score for a politics. That is, you know, you could see how powerful this particular thing. So I hope you found this video useful. And if you have any suggestions for the next videos, let me know in the comment. And if you haven't subscribed, please do subscribe. Thank you.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EFtEStD6MGQZ"
      },
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}