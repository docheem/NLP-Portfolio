{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/docheem/NLP-Portfolio/blob/main/YTVTranscriptionWhisperAPIDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRB4prIxFQvD",
        "outputId": "387b2d4c-b97d-4ab2-b082-5449994fa8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1THkEoXiFGqC"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxVAiYThFGqE"
      },
      "outputs": [],
      "source": [
        "link='https://www.youtube.com/watch?v=dT_aIJZ7Mxw'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgzjYcmBFGqE"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # object creation using YouTube\n",
        "    # which was imported in the beginning\n",
        "    yt = YouTube(link)\n",
        "except:\n",
        "    print(\"Connection Error\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibA2bGLuFGqF",
        "outputId": "3de4bc5b-b7ba-4682-c1b5-32d3f2dc4ce4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">, <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        " yt.streams.filter(file_extension='mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mj3iS5eFGqF"
      },
      "outputs": [],
      "source": [
        "stream = yt.streams.get_by_itag(139)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBbeebEZFGqG",
        "outputId": "933b128d-6cbf-4672-ded9-de96665cceef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/GoogleImagen.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "stream.download('',\"GoogleImagen.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "EFtEStD6MGQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a29b661-ec8f-4a90-aa9c-f02d794ed727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "OPENAI_API_KEY = ''\n",
        "with open('/content/OpenAI.json', 'r') as file_to_read:\n",
        "    json_data = json.load(file_to_read)\n",
        "    OPENAI_API_KEY = json_data[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "kVBXCfpvce6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key =  OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "cjsN_R98ciCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
        "\n",
        "audio_file= open(\"/content/GoogleImagen.mp4\", \"rb\")\n",
        "\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)"
      ],
      "metadata": {
        "id": "m7SnRroic7Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Codna7RYd6Lz",
        "outputId": "07d26fae-f400-4efb-97ff-836bba049356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"text\": \"In this video, let's look at Imagen, a new AI system from Google Brain. So, what is Imagen? Imagen takes a text as an input and then generates images. For example, the text over here is a chrome-plated duck with a golden beak arguing with an angry turtle in a forest. So, this is the text given and this is the image generated. So, how does this system work? So, this system takes text as an input. There is a frozen text encoder which produces a text embedding. This text embedding is then fed into a series of image diffusion models. There is a first text-to-image diffusion model which generates an image. Then there is a super-resolution diffusion model which is used for increasing the resolution. Then you have another super-resolution diffusion model which gives you the final image. And each of these diffusion models takes the text embedding as the input along with the previous output of the previous stage. So, for the text encoder over here, they use a T5XXL encoder to encode the input text into embeddings. Then they have conditional diffusion model maps the text embedding into the various 64x64 images. Then there is a further text conditional super-resolution diffusion model which can up-sample the 64x64 image into the final image. And if you look at the photos over here which have been generated based on the captions, the photo quality and the photo realism is much high when compared to DALY. So, here is another example which they show over here. So, you can click on a word and you can see what is the kind of image which has been generated. For example, a photo of a British short-haired cat wearing a cowboy hat and a red shirt riding a bike on a beach. So, this is the kind of image you get. Now, if you go to the other one, this is an oil painting of the same thing. For example, this is a Persian cat. This is the image which has been generated. So, if you click on fuzzy panda, so for the panda this is the kind of image which has been generated based on this highlighted text caption. So, this is playing a guitar, this is riding a bike, this is skateboarding on top of a mountain. So, this is an oil painting. Now, if you go to photo, you see this photo quality which has been generated. So, this seems much better than DALY and they say that when they looked at the benchmarks over here, they have attained a new state of art score, image fidelity score on, you know, when compared to DALY 2 or the other models on the COCO dataset. So, this is quite interesting work and I am amazed at the pace at which AI is developing now with newer models being developed by these big big research teams achieving newer fascinating results. I hope you like this video on ImageN. If you like the video, please like, share, subscribe to the channel. See you in another video. Happy learning.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFDU68mAd9PK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}